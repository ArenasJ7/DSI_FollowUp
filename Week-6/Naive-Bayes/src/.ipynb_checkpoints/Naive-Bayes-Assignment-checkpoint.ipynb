{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB as SKMultinomialNB\n",
    "from naive_bayes import MultinomialNaiveBayes\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    client = MongoClient()\n",
    "    db = client.nyt_dump\n",
    "    coll = db.articles\n",
    "\n",
    "    articles = coll.find({'$or': [{'section_name':'Sports'},\n",
    "                                  {'section_name': 'Fashion & Style'}]})\n",
    "\n",
    "    article_texts = []\n",
    "    labels = []\n",
    "    for article in articles:\n",
    "        article_texts.append(' '.join(article['content'])), \n",
    "        labels.append(article['section_name'])\n",
    "    return article_texts, np.array(labels)\n",
    " \n",
    "def my_tokenizer(doc):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    article_tokens = tokenizer.tokenize(doc.lower())\n",
    "    return article_tokens\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "    X_tr_toks = [my_tokenizer(doc) for doc in X_train]\n",
    "    X_te_toks = [my_tokenizer(doc) for doc in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNaiveBayes()\n",
    "NB.fit(X_tr_toks, y_train)\n",
    "\n",
    "res = NB.posteriors(X_tr_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122,  44,   1,  47,  56,  27,   0,  50, 110,  81,  79,  32,  67,\n",
       "        52,  46, 130,  38,  59,  86,   8, 131,  74,  23,  93,  22, 112,\n",
       "        66, 117,   7,   9,  11, 106, 109,  61,  58,  84,  29,  76,  19,\n",
       "        41, 118, 100,  70,  17,  88,   6,  63,  69,  90,  77,  15,  82,\n",
       "        43,  89,  26, 133,   5, 101,  78,  18,   2,  96,  85,  49, 113,\n",
       "        37,  40,  31,  72,  60, 120, 115,  24,  71,  99,  53,  98,  65,\n",
       "       104,   4,  51,  25, 128, 123,  57,   3, 125,  28,  73, 121,  12,\n",
       "       126,  20,  83, 127,  21,  33,  55,  30,  10,  42, 103,  62, 132,\n",
       "        36, 129, 124,  95, 111, 107, 108, 119,  35,  14,  94, 116,  80,\n",
       "        48, 114, 102,  39,  13,  16,  87, 105,  68,  64,  92,  91,  97,\n",
       "        34,  45,  54,  75])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = []\n",
    "\n",
    "for i in res:\n",
    "    \n",
    "    dic_value = list(i.values())\n",
    "    disc_value = dic_value[0] / dic_value[1]\n",
    "    disc.append(disc_value)\n",
    "\n",
    "disc = np.array(disc)\n",
    "\n",
    "np.argsort(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bernoulli_naive_bayes import BernoulliNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNB = BernoulliNaiveBayes()\n",
    "BNB.fit(X_tr_toks, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = BNB.posteriors(X_tr_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 122,  44,  90,  85,  46,  15,  78,  20,  32,  99,  26,  77,\n",
       "        79,  52,  27,  50,  59,   7,  61, 100,   5,  83, 130, 101,  81,\n",
       "        56, 110,  38,   6, 117, 112,  37, 125,   0,  86,  47,   8,  22,\n",
       "        23,  41,  67,  58,   9,  74,  93,  11, 106,  63, 109, 131,  88,\n",
       "        84,  82,  28,  69, 118,  43,   3,  96,  30,  70,  17,  40,  33,\n",
       "        31,   2, 115,  66,  76,  25,  57,  19,  51, 121,  72, 120,  29,\n",
       "       113,  18,   4, 128,  98,  24,  53,  49, 133,  71,  89,  65, 123,\n",
       "        12,  21, 126,  60, 104, 127,  73,  16,  55,  75, 114,  97,  34,\n",
       "        68, 103,  10,  91,  80,  36,  14, 108,  94, 124, 111,  62,  39,\n",
       "       132,  42, 129,  35,  87, 116,  95,  48,  92, 119,  64, 102,  54,\n",
       "       107,  13,  45, 105])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = []\n",
    "\n",
    "for i in res:\n",
    "    \n",
    "    dic_value = list(i.values())\n",
    "    disc_value = dic_value[0] / dic_value[1]\n",
    "    disc.append(disc_value)\n",
    "\n",
    "disc = np.array(disc)\n",
    "\n",
    "np.argsort(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
